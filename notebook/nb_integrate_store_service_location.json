{
	"name": "nb_integrate_store_service_location",
	"properties": {
		"folder": {
			"name": "integration/service-location"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "synsppdlinte201",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "7dac8898-50fb-427a-a410-0f6157316bdd"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/68ab6d29-6524-4862-8fb0-8b171dcf03a9/resourceGroups/rg-synw-pdlintegrations-nonprd-dev-e2-01/providers/Microsoft.Synapse/workspaces/synw-pdlintegrations-nonprd-dev-e2-01/bigDataPools/synsppdlinte201",
				"name": "synsppdlinte201",
				"type": "Spark",
				"endpoint": "https://synw-pdlintegrations-nonprd-dev-e2-01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/synsppdlinte201",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"tags": [
						"parameters"
					]
				},
				"source": [
					"BASE_ADLS_CONN_STR = \"abfss://data-integration@sasynwpdlintnpdeve201.dfs.core.windows.net/\"\r\n",
					"OPCO=\"gntc\"\r\n",
					"TARGET_RTL_STORE_ZIP_PATH = \"opco/{opco}/domain/store/retailer-cpt-store-zip/master/\"\r\n",
					"TARGET_RTL_ECOM_STORE_CTL_PATH = \"opco/{opco}/domain/store/retailer-cpt-ecom-store-ctl/master/\"\r\n",
					"TARGET_CNTRL_PUP_CTL_PATH = \"opco/{opco}/domain/store/central-cit-pup-ctl/master/\"\r\n",
					"TARGET_RTL_ZIP_LAT_LONG_PATH = \"opco/{opco}/domain/store/retailer-cpt-zip-lat-long/master/\"\r\n",
					"TARGET_RTL_USER_VAR_PATH = \"opco/{opco}/domain/store/retailer-cpt-user-var/master/\"\r\n",
					"TARGET_RTL_STORE_GRP_PATH = \"opco/{opco}/domain/store/retailer-cpt-store-grp/master/\"\r\n",
					"TARGET_CNTRL_PR_ZONE_XREF_PATH = \"opco/{opco}/domain/store/central-pit-pr-zone-xref/master/\"\r\n",
					"TARGET_CNTRL_ZONE_CTL_PATH = \"opco/{opco}/domain/store/central-cit-zone-ctl/master/\"\r\n",
					"TARGET_CNTRL_STORE_ZIP_PATH = \"opco/{opco}/domain/store/central-cit-store-zip/master/\"\r\n",
					"TARGET_SERVICE_LOCATION=\"opco/{opco}/integration/service-location/service-locations/master\"\r\n",
					"STG_FLAG= True\r\n",
					"VAL_CNT_THRESHOLD=2"
				],
				"execution_count": 381
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**INCLUDE UTILS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run utils/logging/nb_logging_util { LOGGER_NM: \"nb_integrate_store_service_location\", LOGGING_LEVEL: \"INFO\" }"
				],
				"execution_count": 382
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run utils/validation/nb_auto_data_validation_framework"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\r\n",
					"logger.info(\"*************************************************************************\") \r\n",
					"logger.info(\"\\t STORE INTEGRATION - SERVIVE LOCATIONS - Starting with below parameters\")\r\n",
					"logger.info(\"*************************************************************************\")\r\n",
					"logger.info(\"\\t TARGET_RTL_STORE_ZIP_PATH : {0}\".format(TARGET_RTL_STORE_ZIP_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_RTL_ECOM_STORE_CTL_PATH : {0}\".format(TARGET_RTL_ECOM_STORE_CTL_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_CNTRL_PUP_CTL_PATH : {0}\".format(TARGET_CNTRL_PUP_CTL_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_RTL_ZIP_LAT_LONG_PATH : {0}\".format(TARGET_RTL_ZIP_LAT_LONG_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_RTL_USER_VAR_PATH : {0}\".format(TARGET_RTL_USER_VAR_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_CNTRL_PR_ZONE_XREF_PATH : {0}\".format(TARGET_CNTRL_PR_ZONE_XREF_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_CNTRL_ZONE_CTL_PATH : {0}\".format(TARGET_CNTRL_ZONE_CTL_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t TARGET_CNTRL_STORE_ZIP_PATH : {0}\".format(TARGET_CNTRL_STORE_ZIP_PATH.format(opco = OPCO)))\r\n",
					"logger.info(\"\\t OPCO : {0}\".format(OPCO))\r\n",
					"logger.info(\"\\t VAL_CNT_THRESHOLD : {0}\".format(VAL_CNT_THRESHOLD))\r\n",
					"logger.info(\"**************************************************************************\")"
				],
				"execution_count": 383
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**LOADING DATA FROM MASTER**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from delta.tables import DeltaTable\r\n",
					"\r\n",
					"\r\n",
					"def check_if_master_file_exists():\r\n",
					"    \r\n",
					"    return DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_RTL_STORE_ZIP_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_RTL_ECOM_STORE_CTL_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_CNTRL_PUP_CTL_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_RTL_ZIP_LAT_LONG_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_RTL_USER_VAR_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_RTL_STORE_GRP_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_CNTRL_PR_ZONE_XREF_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_CNTRL_ZONE_CTL_PATH.format(opco = OPCO)) & \\\r\n",
					"           DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_CNTRL_STORE_ZIP_PATH.format(opco = OPCO))\r\n",
					"\r\n",
					"is_master_fl_exist = check_if_master_file_exists()\r\n",
					"if is_master_fl_exist: \r\n",
					"    \r\n",
					"    df_store_zip_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_RTL_STORE_ZIP_PATH.format(opco = OPCO))                             \r\n",
					"\r\n",
					"\r\n",
					"    df_ecom_stor_ctl_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_RTL_ECOM_STORE_CTL_PATH.format(opco = OPCO))                    \r\n",
					"\r\n",
					"\r\n",
					"    df_pup_ctl_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_CNTRL_PUP_CTL_PATH.format(opco = OPCO)) \r\n",
					"                                \r\n",
					"\r\n",
					"    df_zip_lat_long_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_RTL_ZIP_LAT_LONG_PATH.format(opco = OPCO)) \r\n",
					"\r\n",
					"    df_user_var_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_RTL_USER_VAR_PATH.format(opco = OPCO))\r\n",
					"\r\n",
					"    df_store_grp_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_RTL_STORE_GRP_PATH.format(opco = OPCO))\r\n",
					"\r\n",
					"    df_pr_zone_xref_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_CNTRL_PR_ZONE_XREF_PATH.format(opco = OPCO)) \r\n",
					"                                \r\n",
					"    df_zone_ctl_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_CNTRL_ZONE_CTL_PATH.format(opco = OPCO))                             \r\n",
					"\r\n",
					"    df_cntrl_store_zip_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_CNTRL_STORE_ZIP_PATH.format(opco = OPCO)) \r\n",
					"else:\r\n",
					"    logger.error(\"Master file does not exist for OPCO={0}\".format(OPCO))\r\n",
					"    raise Exception(\"MASTER_FILE_DOES_NOT_EXIST\") \r\n",
					"\r\n",
					"df_store_zip_master.createOrReplaceTempView(\"tbl_store_zip\")\r\n",
					"df_ecom_stor_ctl_master.createOrReplaceTempView(\"tbl_ecom_stor_ctl\")\r\n",
					"df_pup_ctl_master.createOrReplaceTempView(\"tbl_pup_ctl\")\r\n",
					"df_zip_lat_long_master.createOrReplaceTempView(\"tbl_zip_lat_long\")  \r\n",
					"df_zone_ctl_master.createOrReplaceTempView(\"tbl_zone_ctl\")\r\n",
					"df_user_var_master.createOrReplaceTempView(\"tbl_user_var\")\r\n",
					"df_pr_zone_xref_master.createOrReplaceTempView(\"tbl_pr_zone_xref\")\r\n",
					"df_cntrl_store_zip_master.createOrReplaceTempView(\"tbl_cntrl_store_zip\")\r\n",
					" \r\n",
					"logger.info(\"\\t DATA LOAD:  RETAILER:cpt_stor_zip,  RETAILER:ecom_stor_ctl, \\n RETAILER:cpt_zip_lat_long, RETAILER:cpt_user_var,\\n RETAILER:cpt_stor_grp, CENTRAL:cit_pup_ctl,\\n CENTRAL:cit_zone_ctl, CENTRAL:cit_stor_zip, \\nCENTRAL:pit_pr_zone_xref from master\")\r\n",
					""
				],
				"execution_count": 384
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**SERVICE LOCATIONS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from delta.tables import DeltaTable\r\n",
					"from pyspark.sql.functions import upper,expr\r\n",
					"\r\n",
					"\r\n",
					"df_service_locations= spark.sql(\"\"\"\r\n",
					"SELECT DISTINCT c.stor_zip_id, c.zip_cd, c.city_tx, c.st_cd, c.support_site  AS support_site,c.sit_support_site  AS stg_support_site, \r\n",
					"               z2.support_site AS pickup_siblingSite, z2.sit_support_site AS stg_pickup_siblingSite, c.ecom_stor_id, c.user_type_cd, \r\n",
					"               c.dlv_area_id, c.pup_guid_cd,c.svc_type_cd, c.stop_time_cd, c.pr_zone_cd, c.tax_grp_cd, c.time_diff_qy, c.subs_pr_tier_id,\r\n",
					"               e.stag_only_fl AS store_stagOnly, e.opco_id, p.pup_guid_cd AS pup_guid,p.stor_ttl_tx, p.web_actv_cd, p.adr_1_tx, p.adr_2_tx,\r\n",
					"               p.pup_voic_phon_cd, p.lat_qy,p.long_qy, p.loc_istr_tx, p.ahld_stor_nbr_cd, e.stor_stat_cd, p.map_web_link_tx, p.pup_type_cd,\r\n",
					"               p.stag_only_fl AS pup_stagOnly, z2.stor_zip_id AS pup_sibling, e.stor_id AS storeCode,e.ortc_stor_fl AS ortc_stor_fl_old,\r\n",
					"               ll.cntr_lat_qy AS latitude, ll.cntr_long_qy AS longitude,\r\n",
					"          CASE WHEN c.svc_type_cd in ('P','B') THEN NVL(p.ortc_stor_fl, 'N')\r\n",
					"               WHEN c.svc_type_cd = 'D' AND NVL(d.pup_id, 0) between 0 AND 10000 THEN NVL(z.ortc_stor_fl, 'N')\r\n",
					"               WHEN c.svc_type_cd = 'D' AND NVL(d.pup_id, 0) >= 10000 THEN NVL(dp.ortc_stor_fl, 'N')\r\n",
					"               ELSE 'N' END ortc_stor_fl,               \r\n",
					"          CASE WHEN c.svc_type_cd IN ('P','B') THEN p.pup_id\r\n",
					"               WHEN c.svc_type_cd = 'D' THEN d.pup_id\r\n",
					"               ELSE null END pup_id\r\n",
					"          FROM tbl_store_zip c join tbl_ecom_stor_ctl e ON (c.ecom_stor_id=e.ecom_stor_id)\r\n",
					"          LEFT OUTER JOIN tbl_zip_lat_long AS ll ON ll.zip_cd = c.zip_cd                        \r\n",
					"          LEFT OUTER JOIN tbl_pup_ctl AS p ON (c.pup_guid_cd=p.pup_guid_cd AND c.pup_guid_cd != '0' AND (c.svc_type_cd='P' OR c.svc_type_cd='B'))\r\n",
					"          LEFT OUTER JOIN tbl_store_zip AS z2 ON (c.svc_type_cd='B' AND c.pup_guid_cd=z2.pup_guid_cd AND c.zip_cd=z2.zip_cd AND\r\n",
					"               c.city_tx=z2.city_tx AND c.st_cd=z2.st_cd AND c.ecom_stor_id=z2.ecom_stor_id AND c.user_type_cd=z2.user_type_cd AND z2.svc_type_cd='P')\r\n",
					"          LEFT OUTER JOIN tbl_cntrl_store_zip AS d on (c.svc_type_cd='D' AND c.zip_cd=d.zip_cd AND c.city_tx=d.city_tx AND \r\n",
					"               c.st_cd=d.st_cd AND e.stor_id=d.stor_id AND c.user_type_cd=d.mbr_type_cd AND c.dlv_area_id = d.dlv_area_id AND d.svc_type_cd='D')\r\n",
					"          LEFT OUTER JOIN tbl_zone_ctl AS z ON (z.stor_id = e.stor_id) \r\n",
					"          LEFT OUTER JOIN tbl_pup_ctl AS dp ON (d.pup_id=dp.pup_id AND d.pup_id != '0' AND (d.svc_type_cd='D'))\r\n",
					"          WHERE c.dlv_area_id != 800 AND e.opco_id='\"\"\"+ OPCO.upper() +\"\"\"' AND ((c.svc_type_cd in  ('P', 'B') AND p.pup_guid_cd is not null) OR (c.svc_type_cd in  ('D')))\r\n",
					"          ORDER BY c.stor_zip_id ;\r\n",
					"           \"\"\")\r\n",
					"\r\n",
					"logger.info(\"\\t INTEGRATION:Integrated the loaded data for service locations.\\n OPCO={0},\\n Count={1}\".format(OPCO,df_service_locations.count()))"
				],
				"execution_count": 385
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**LOCATION NUMBER**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"join_cond_1 = df_pr_zone_xref_master[\"pr_zone_cd\"] ==  df_store_zip_master[\"pr_zone_cd\"]\r\n",
					"join_cond_2 =  df_store_zip_master[\"ecom_stor_id\"] == df_ecom_stor_ctl_master[\"ecom_stor_id\"]\r\n",
					"where_cond = (df_ecom_stor_ctl_master[\"opco_id\"] == OPCO.upper()) & \\\r\n",
					"                  (df_pr_zone_xref_master[\"pr_zone_type_cd\"] == \"B\") & \\\r\n",
					"                  (df_store_zip_master[\"ecom_stor_id\"].isNotNull()) & \\\r\n",
					"                  (df_pr_zone_xref_master[\"rml_in_fld_cd\"].isNotNull()) & \\\r\n",
					"                  (df_pr_zone_xref_master[\"rml_in_fld_cd\"] != \"\")\r\n",
					"\r\n",
					"df_price_zone_xref = df_pr_zone_xref_master \\\r\n",
					"                            .join( df_store_zip_master, join_cond_1, \"left\") \\\r\n",
					"                            .join(df_ecom_stor_ctl_master, join_cond_2, \"left\") \\\r\n",
					"                            .where(where_cond) \\\r\n",
					"                            .select(df_pr_zone_xref_master[\"pr_zone_cd\"],\r\n",
					"                                df_pr_zone_xref_master[\"rml_in_fld_cd\"].alias(\"stor_num\"),\r\n",
					"                                df_pr_zone_xref_master[\"banr_id\"],\r\n",
					"                                df_store_zip_master[\"ecom_stor_id\"],\r\n",
					"                                df_ecom_stor_ctl_master[\"stor_id\"],\r\n",
					"                                df_ecom_stor_ctl_master[\"opco_id\"]).distinct()\r\n",
					"\r\n",
					"logger.info(\"\\t PRICE ZONE XREF: Data extracted for stor_num.\\n OPCO={0},\\n Path={1},\\n Count={2}\".format(OPCO,TARGET_CNTRL_PR_ZONE_XREF_PATH.format(opco = OPCO),df_price_zone_xref.count()))\r\n",
					"df_service_locations = df_service_locations.join(df_price_zone_xref,on=[\"ecom_stor_id\",\"opco_id\",\"pr_zone_cd\"], how=\"left\").select(df_service_locations[\"*\"],df_price_zone_xref[\"stor_num\"])\r\n",
					"\r\n",
					"df_service_locations.createOrReplaceTempView(\"tbl_service_locations\")\r\n",
					"logger.info(\"\\t LOCATION NUMBER: Enriched service locations with stor_num.\\n OPCO={0},\\n Count={1}\".format(OPCO,df_service_locations.count()))"
				],
				"execution_count": 386
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**USER VARIABLES**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col\r\n",
					"df_user_variables = df_user_var_master \\\r\n",
					"                        .where(~col(\"var_cd\").isin(\"dflt_g100_fee\", \"tlpd_ord_fee\")) \\\r\n",
					"                        .select(col(\"ecom_stor_id\"),\r\n",
					"                            col(\"user_type_cd\"),\r\n",
					"                            col(\"var_cd\"),\r\n",
					"                            col(\"acct_cd\"),\r\n",
					"                            col(\"var_qy\")) \\\r\n",
					"                        .orderBy(col(\"ecom_stor_id\"),\r\n",
					"                            col(\"user_type_cd\"))\r\n",
					"\r\n",
					"logger.info(\"\\t Filtered data from user_var table.\\n OPCO={0},\\n Count={1}\".format(OPCO,df_user_variables.count()))"
				],
				"execution_count": 387
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**PICKUP FEE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col, when, max, lit, struct, round\r\n",
					"\r\n",
					"\r\n",
					"df_pickup=df_user_variables.groupBy(\"ecom_stor_id\",\"user_type_cd\").agg(\r\n",
					"    max(when(col(\"var_cd\")==\"pckp_ord_fee\",col(\"var_qy\"))).alias(\"fee\"),\r\n",
					"    max(when(col(\"var_cd\")==\"pckp_ord_fee\",col(\"acct_cd\"))).alias(\"accounting_code\")) \r\n",
					"    \r\n",
					"\r\n",
					"pickup_fee_struct=struct(\r\n",
					"        lit(0.0).alias(\"min_cart\"),\r\n",
					"        lit(3.4028235).alias(\"max_cart\"),\r\n",
					"        round(col('fee'),2).alias(\"fee\"),\r\n",
					"        col('accounting_code')\r\n",
					")\r\n",
					"df_pickup_fee=df_pickup.withColumn(\"pickup_fee\",pickup_fee_struct).select(\"ecom_stor_id\",\"user_type_cd\",\"pickup_fee\")"
				],
				"execution_count": 388
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**DELIVERY LEVEL2 FEE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col, when, max, lit\r\n",
					"\r\n",
					"df_delivery_fee_lvl2_qy = df_user_variables.where(col(\"var_cd\")==\"level2_ord_qy\") \\\r\n",
					"                                        .groupBy(\"ecom_stor_id\",\"user_type_cd\").agg(\r\n",
					"                                                        max(\"var_qy\").alias(\"max_cart\")\r\n",
					"                                                        )\r\n",
					"\r\n",
					"df_delivery_fee_lvl2_fee = df_user_variables.where(col(\"var_cd\")==\"level2_ord_fee\") \\\r\n",
					"                                        .groupBy(\"ecom_stor_id\",\"user_type_cd\").agg(\r\n",
					"                                                        max(\"var_qy\").alias(\"fee\"),\r\n",
					"                                                        max(\"acct_cd\").alias(\"accounting_code\")\r\n",
					"                                                        )\r\n",
					"df_delivery_fee_lvl2 = df_delivery_fee_lvl2_qy.join(df_delivery_fee_lvl2_fee,[\"ecom_stor_id\",\"user_type_cd\"], how=\"inner\")   \r\n",
					"\r\n",
					"df_delivery_fee_lvl2_final=df_delivery_fee_lvl2.withColumn(\"min_cart\",lit(0.0)) \\\r\n",
					"                                      .withColumn(\"fee\",round(col('fee'),2)) \\\r\n",
					"                                      .select(\"ecom_stor_id\",\"user_type_cd\",\"min_cart\",\"max_cart\",\"fee\",\"accounting_code\")\r\n",
					""
				],
				"execution_count": 389
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**DELIVERY LEVEL3 FEE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col, when, max, lit, least\r\n",
					"from pyspark.sql import functions as F\r\n",
					"\r\n",
					"df_delivery_fee_lvl3_qy=df_user_variables.where(col(\"var_cd\")==\"level3_ord_qy\") \\\r\n",
					"                                    .groupBy(\"ecom_stor_id\",\"user_type_cd\").agg(\r\n",
					"                                                    max(\"var_qy\").alias(\"min_cart\"),\r\n",
					"                                                    max(\"var_qy\").alias(\"max_cart\")\r\n",
					"                                                    )\r\n",
					" \r\n",
					"df_delivery_fee_lvl3_fee=df_user_variables.where(col(\"var_cd\")==\"level3_ord_fee\") \\\r\n",
					"                                    .groupBy(\"ecom_stor_id\",\"user_type_cd\").agg(\r\n",
					"                                                    max(\"var_qy\").alias(\"fee\"),\r\n",
					"                                                    max(\"acct_cd\").alias(\"accounting_code\")\r\n",
					"                                                    )\r\n",
					"df_delivery_fee_lvl3 = df_delivery_fee_lvl3_qy.join(df_delivery_fee_lvl3_fee,[\"ecom_stor_id\",\"user_type_cd\"], how=\"inner\")\r\n",
					"\r\n",
					"df_delivery_fee_lvl3_final = df_delivery_fee_lvl3.join(df_delivery_fee_lvl2_final, (df_delivery_fee_lvl3.ecom_stor_id == df_delivery_fee_lvl2_final.ecom_stor_id) & (df_delivery_fee_lvl3.user_type_cd == df_delivery_fee_lvl2.user_type_cd), 'left') \\\r\n",
					"                                                .select(least(df_delivery_fee_lvl3.max_cart, \r\n",
					"                                                                when(df_delivery_fee_lvl2_final.max_cart.isNotNull(), df_delivery_fee_lvl2_final.max_cart)\r\n",
					"                                                                .otherwise(0.0)).alias('min_cart'),\r\n",
					"                                                        df_delivery_fee_lvl3.max_cart,\r\n",
					"                                                        df_delivery_fee_lvl3.accounting_code,\r\n",
					"                                                        df_delivery_fee_lvl3.fee,\r\n",
					"                                                        df_delivery_fee_lvl3.ecom_stor_id,\r\n",
					"                                                        df_delivery_fee_lvl3.user_type_cd\r\n",
					"                                                        )\r\n",
					""
				],
				"execution_count": 390
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**DELIVERY STANDARD FEE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col, when, max, lit, coalesce\r\n",
					"\r\n",
					"\r\n",
					"df_delivery_std=df_user_variables.where(col(\"var_cd\")==\"std_ord_fee\") \\\r\n",
					"                                .groupBy(\"ecom_stor_id\",\"user_type_cd\").agg(\r\n",
					"                                                max(\"var_qy\").alias(\"fee\"),\r\n",
					"                                                max(\"acct_cd\").alias(\"accounting_code\")\r\n",
					"                                                )\r\n",
					"df_delivery_fee_std=df_delivery_std.select(\"ecom_stor_id\",\"user_type_cd\",\r\n",
					"                                                lit(0.0).alias(\"min_cart\"),\r\n",
					"                                                lit(3.4028235).alias(\"max_cart\"),\r\n",
					"                                                col(\"fee\"),\r\n",
					"                                                col(\"accounting_code\"))\r\n",
					"\r\n",
					"df_delivery_fee_std_final = df_delivery_fee_std \\\r\n",
					"                        .join(df_delivery_fee_lvl2_final, on=[\"ecom_stor_id\",\"user_type_cd\"], how= 'left') \\\r\n",
					"                        .join(df_delivery_fee_lvl3_final, on=[\"ecom_stor_id\",\"user_type_cd\"],how= 'left') \\\r\n",
					"                        .select(\r\n",
					"                                coalesce(df_delivery_fee_lvl3_final.max_cart, df_delivery_fee_lvl2_final.max_cart,lit(0.00)).alias(\"min_cart\"),\r\n",
					"                                df_delivery_fee_std.max_cart,\r\n",
					"                                df_delivery_fee_std.fee,\r\n",
					"                                df_delivery_fee_std.accounting_code,\r\n",
					"                                df_delivery_fee_std.ecom_stor_id,\r\n",
					"                                df_delivery_fee_std.user_type_cd\r\n",
					"                        )"
				],
				"execution_count": 391
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**DELIVERY FEE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_delivery_fee_lvl3_filtered=df_delivery_fee_lvl3_final.where(df_delivery_fee_lvl3_final.max_cart > when(df_delivery_fee_lvl2_final.max_cart.isNotNull(), df_delivery_fee_lvl2_final.max_cart).otherwise(0.0))\r\n",
					"df_delivery_fee=df_delivery_fee_lvl2_final.unionByName(df_delivery_fee_lvl3_filtered).unionByName(df_delivery_fee_std_final)\r\n",
					"df_delivery_fee=df_delivery_fee.withColumn(\"dlvry_fee\",struct(\"min_cart\",\"max_cart\",round(col('fee'),2).alias(\"fee\"),\"accounting_code\")).select(\"ecom_stor_id\",\"user_type_cd\",\"dlvry_fee\")"
				],
				"execution_count": 392
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**LEGACY FEE AMOUNTS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col, when, max,struct,create_map, lit, col,round\r\n",
					"\r\n",
					"df_LegFee = df_user_variables.groupBy(\"ecom_stor_id\", \"user_type_cd\").agg(\r\n",
					"    max(when(col(\"var_cd\") == \"std_ord_fee\", col(\"var_qy\"))).alias(\"standardFee\"),\r\n",
					"    max(when(col(\"var_cd\") == \"level2_ord_fee\", col(\"var_qy\"))).alias(\"level2Fee\"),\r\n",
					"    max(when(col(\"var_cd\") == \"level2_ord_qy\", col(\"var_qy\"))).alias(\"level2Qty\"),\r\n",
					"    max(when(col(\"var_cd\") == \"level3_ord_fee\", col(\"var_qy\"))).alias(\"level3Fee\"),\r\n",
					"    max(when(col(\"var_cd\") == \"level3_ord_qy\", col(\"var_qy\"))).alias(\"level3Qty\"),\r\n",
					"    max(when(col(\"var_cd\") == \"pckp_ord_fee\", col(\"var_qy\"))).alias(\"pickupFee\"),\r\n",
					"    max(when(col(\"var_cd\") == \"min_send_ord_qy\", col(\"var_qy\"))).alias(\"minimumDeliveryAmount\"),\r\n",
					"    max(when(col(\"var_cd\") == \"pckp_send_ord_qy\", col(\"var_qy\"))).alias(\"minimumPickupAmount\")) \r\n",
					"    \r\n",
					"df_LegFee = df_LegFee.withColumn(\"legacy_fee_amounts\",create_map(lit('standardFee'),col('standardFee'),\r\n",
					"                                                               lit('level2Fee'),col('level2Fee'),\r\n",
					"                                                               lit('level2Qty'),col('level2Qty'),\r\n",
					"                                                               lit('level3Fee'),col('level3Fee'),\r\n",
					"                                                               lit('level3Qty'),col('level3Qty'),\r\n",
					"                                                               lit('pickupFee'),col('pickupFee'),\r\n",
					"                                                               lit('minimumDeliveryAmount'),col('minimumDeliveryAmount'),\r\n",
					"                                                               lit('minimumPickupAmount'),col('minimumPickupAmount')\r\n",
					"                                                               ))\r\n",
					""
				],
				"execution_count": 393
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**JOINING PICKUP FEE, DELIVERY FEE, LEGACY FEE TO SERVICE LOCATIONS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import collect_list\r\n",
					"\r\n",
					"df_with_pickup=df_service_locations.join(df_pickup_fee,[\"ecom_stor_id\", \"user_type_cd\"],\"left\").filter(col(\"svc_type_cd\")=='P') \\\r\n",
					"                                    .select(\"ecom_stor_id\", \"user_type_cd\",\"svc_type_cd\",\"pickup_fee\",\"stor_zip_id\")\r\n",
					"df_with_deliv=df_service_locations.join(df_delivery_fee,[\"ecom_stor_id\", \"user_type_cd\"],\"left\").filter((df_service_locations[\"svc_type_cd\"]=='D') | (df_service_locations[\"svc_type_cd\"]=='B')) \\\r\n",
					"                                    .select(\"ecom_stor_id\", \"user_type_cd\",\"svc_type_cd\",\"dlvry_fee\",\"stor_zip_id\")\r\n",
					"df_service_locations=df_service_locations.join(df_with_pickup,[\"ecom_stor_id\", \"user_type_cd\",\"svc_type_cd\",\"stor_zip_id\"],\"left\") \\\r\n",
					"                                        .join(df_with_deliv,[\"ecom_stor_id\", \"user_type_cd\",\"svc_type_cd\",\"stor_zip_id\"],\"left\")                                \r\n",
					"\r\n",
					"all_columns=df_service_locations.columns\r\n",
					"grouped_cols=[col for col in all_columns if col!='dlvry_fee']\r\n",
					"df_service_locations=df_service_locations.groupBy(*grouped_cols).agg(collect_list(\"dlvry_fee\").alias(\"delivery_fee\"))\r\n",
					"df_service_locations=df_service_locations.join(df_LegFee,[\"ecom_stor_id\", \"user_type_cd\"],\"left\")\r\n",
					"\r\n",
					"logger.info(\"\\tService Locations data after joinig pickup fee, delivery fee, legacy fee amount.\\n OPCO={0},\\n Count={1}\".format(OPCO,df_service_locations.count()))"
				],
				"execution_count": 394
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**MINIMUM ORDER FOR CHECK OUT**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col\r\n",
					"pickup_con=(col(\"a.svc_type_cd\").isin(\"P\",\"B\") & (col(\"b.var_cd\")==\"pckp_send_ord_qy\"))\r\n",
					"delivery_con=(col(\"a.svc_type_cd\")==\"D\") & (col(\"b.var_cd\")==\"min_send_ord_qy\")\r\n",
					"pickup_select_exprs=[\r\n",
					"                col(\"a.ecom_stor_id\").alias(\"ecom_stor_id\"),\r\n",
					"                col(\"a.user_type_cd\").alias(\"user_type_cd\"),\r\n",
					"                col(\"a.stor_zip_id\").alias(\"stor_zip_id\"),\r\n",
					"                round(col(\"b.var_qy\"),2).alias(\"minimum_order_for_checkout\")\r\n",
					"            ]\r\n",
					"delivery_select_exprs=pickup_select_exprs\r\n",
					"pickup_query=df_service_locations.alias(\"a\") \\\r\n",
					"                .join(df_user_variables.alias(\"b\"),[\"ecom_stor_id\",\"user_type_cd\"]) \\\r\n",
					"                .where(pickup_con) \\\r\n",
					"                .select(*pickup_select_exprs)\r\n",
					"delivery_query=df_service_locations.alias(\"a\") \\\r\n",
					"                .join(df_user_variables.alias(\"b\"),[\"ecom_stor_id\",\"user_type_cd\"]) \\\r\n",
					"                .where(delivery_con) \\\r\n",
					"                .select(*delivery_select_exprs)\r\n",
					"df_minorder=pickup_query.unionAll(delivery_query)\r\n",
					"\r\n",
					"logger.info(\"\\t Minimum Order For Checkout: Enriched minimum_order_for_checkout for service locations.\\n Count={0}\".format(df_minorder.count()))"
				],
				"execution_count": 395
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**NAMING SERVICE LOCATION COLUMNS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import array, col, when, lit, coalesce, expr\r\n",
					"df_service_locs=df_service_locations.withColumn(\"id\",col(\"stor_zip_id\").cast(\"string\")) \\\r\n",
					"                                        .withColumnRenamed(\"stor_num\",\"location_number\") \\\r\n",
					"                                        .withColumnRenamed(\"ecom_stor_id\",\"ecomm_store_id\") \\\r\n",
					"                                        .withColumnRenamed(\"opco_id\",\"opco\") \\\r\n",
					"                                        .withColumnRenamed(\"stor_ttl_tx\",\"name\") \\\r\n",
					"                                        .withColumnRenamed(\"adr_1_tx\",\"address\") \\\r\n",
					"                                        .withColumnRenamed(\"adr_2_tx\",\"address2\") \\\r\n",
					"                                        .withColumnRenamed(\"city_tx\",\"city\") \\\r\n",
					"                                        .withColumnRenamed(\"st_cd\",\"state\") \\\r\n",
					"                                        .withColumnRenamed(\"pup_type_cd\",\"pickup_point_type\") \\\r\n",
					"                                        .withColumnRenamed(\"zip_cd\",\"zip\") \\\r\n",
					"                                        .withColumnRenamed(\"map_web_link_tx\",\"map_url\") \\\r\n",
					"                                        .withColumn(\"location\",array(coalesce(col(\"long_qy\"),lit(0.0)),coalesce(col(\"lat_qy\"),lit(0.0)))) \\\r\n",
					"                                        .withColumnRenamed(\"pup_voic_phon_cd\",\"phone_number\") \\\r\n",
					"                                        .withColumn(\"web_active\",when(col(\"web_actv_cd\")==\"Y\",True).otherwise(False)) \\\r\n",
					"                                        .withColumnRenamed(\"loc_istr_tx\",\"instructions\") \\\r\n",
					"                                        .withColumnRenamed(\"user_type_cd\",\"user_type\") \\\r\n",
					"                                        .withColumnRenamed(\"dlv_area_id\",\"delivery_area_id\") \\\r\n",
					"                                        .withColumnRenamed(\"time_diff_qy\",\"time_diff_qy\") \\\r\n",
					"                                        .withColumnRenamed(\"pr_zone_cd\",\"price_zone\") \\\r\n",
					"                                        .withColumnRenamed(\"subs_pr_tier_id\",\"subscription_price_zone\") \\\r\n",
					"                                        .withColumnRenamed(\"svc_type_cd\",\"service_type\") \\\r\n",
					"                                        .withColumnRenamed(\"stor_stat_cd\",\"store_status_code\") \\\r\n",
					"                                        .withColumnRenamed(\"tax_grp_cd\",\"tax_grp_cd\") \\\r\n",
					"                                        .withColumnRenamed(\"pup_guid_cd\",\"pickup_location_id\") \\\r\n",
					"                                        .withColumnRenamed(\"pup_guid\",\"checked_pickup_location_id\") \\\r\n",
					"                                        .withColumn(\"store_staging_only\",when(col(\"store_stagOnly\")==\"Y\",True).otherwise(False)) \\\r\n",
					"                                        .withColumn(\"pup_staging_only\",when(col(\"pup_stagOnly\")==\"Y\",True).otherwise(False)) \\\r\n",
					"                                        .withColumn(\"pickup_sibling\",col(\"pup_sibling\").cast(\"string\")) \\\r\n",
					"                                        .withColumnRenamed(\"storeCode\",\"store_id\") \\\r\n",
					"                                        .withColumn(\"site\",when(lit(STG_FLAG), \r\n",
					"                                                                when(col(\"stg_support_site\").isNull(),\"prism\").otherwise(col(\"stg_support_site\"))\r\n",
					"                                                                ).otherwise(when(col(\"support_site\").isNull(),\"prism\").otherwise(col(\"support_site\")))) \\\r\n",
					"                                        .withColumn(\"pickup_sibling_site\",when(lit(STG_FLAG),\r\n",
					"                                                                when(col(\"stg_pickup_siblingSite\").isNull(),\"prism\").otherwise(col(\"stg_pickup_siblingSite\"))\r\n",
					"                                                                ).otherwise(when(col(\"pickup_siblingSite\").isNull(),\"prism\").otherwise(col(\"pickup_siblingSite\")))) \\\r\n",
					"                                        .withColumn(\"ortec_enabled\",when(col(\"ortc_stor_fl\")==\"Y\",True).otherwise(False)) \\\r\n",
					"                                        .withColumn(\"location_centroid\",array(col(\"longitude\"),col(\"latitude\"))) \\\r\n",
					"                                        .withColumnRenamed(\"pup_id\",\"pup_id\") \\\r\n",
					"                                        .withColumn(\"fees\",expr(\"filter(array_union(array(pickup_fee),delivery_fee),x -> x IS NOT NULL)\")) \\\r\n",
					"                                        .drop(\"web_actv_cd\",\" store_stagOnly\",\"pup_stagOnly\",\"ortc_stor_fl\",\"longitude\",\"latitude\",\"stor_zip_id\",\"pup_sibling\")\r\n",
					"logger.info(\"\\t Renaming and Enriching: service location columns.\\n Count={0}\".format(df_service_locs.count()))\r\n",
					""
				],
				"execution_count": 396
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**ACTIVE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"active_con= (\r\n",
					"                (col(\"store_status_code\")==\"ACTIVE\")\r\n",
					"                    & (\r\n",
					"                (col(\"service_type\")==\"D\") & (col(\"site\")==\"prism\")\r\n",
					"                    | ((col(\"service_type\").isin(\"P\",\"B\")) & (col(\"web_active\")==True))\r\n",
					"                        )\r\n",
					"                    )\r\n",
					"df_service_locs=df_service_locs.withColumn(\"active\",when(active_con,True).otherwise(False))\r\n",
					"\r\n",
					"logger.info(\"\\t ACTIVE: Adding active to service locations.\\n Count={0}\".format(df_service_locs.count()))"
				],
				"execution_count": 397
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**PICKUP SIBLING ENABLED**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_service_locs=df_service_locs.withColumn(\"pickup_sibling_enabled\", when (lit(STG_FLAG)== True,(~col(\"pup_Staging_only\"))) \\\r\n",
					"                                                                        .when(((col(\"web_active\")== True) & (col(\"service_type\")==\"ACTIVE\")),True) \\\r\n",
					"                                                                        .otherwise(False))\r\n",
					"logger.info(\"\\t Pickup Sibling Enabled: Adding pickup_sibling_enabled to service locations.\\n Count={0}\".format(df_service_locs.count()))"
				],
				"execution_count": 398
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**PHYSICAL GROCARY STORE**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import collect_set, array_contains,trim\r\n",
					"\r\n",
					"df_click_locations= df_service_locs.filter(col(\"pickup_point_type\")==\"CLICK\")\r\n",
					"df_click_locations=df_click_locations.select(\"price_zone\").groupBy().agg(collect_set(\"price_zone\").alias(\"priceZone_arr\"))\r\n",
					"df_service_locs=df_service_locs.crossJoin(df_click_locations)\r\n",
					"df_service_locs=df_service_locs.withColumn(\"physical_grocery_store\", array_contains(df_click_locations[\"priceZone_arr\"],df_service_locs[\"price_zone\"])).drop(col(\"priceZone_arr\"))\r\n",
					"logger.info(\"\\t Physical Grocery Store: Enriching service locations with physical_grocery_store.\\n Count={0}\".format(df_service_locs.count()))\r\n",
					""
				],
				"execution_count": 399
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**STORE GROUPS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from pyspark.sql.functions import col, explode\r\n",
					"from pyspark.sql import functions as F\r\n",
					"\r\n",
					"df_svc_locs_selected=df_service_locs.select(\"ecomm_store_id\",\"zip\",\"location_number\",\"price_zone\")\r\n",
					"\r\n",
					"# df_svc_locs_selected=df_svc_locs_selected.distinct()\r\n",
					"df_stor_grp_ecom_stor_id = df_store_grp_master.withColumn(\"ecom_storeIds\",explode(df_store_grp_master.ecom_store_ids)) \\\r\n",
					"                                              .withColumnRenamed(\"grp_id\",\"grp_id_ecom\").select(\"grp_id_ecom\",\"ecom_storeIds\")\r\n",
					"\r\n",
					"df_stor_grp_zip = df_store_grp_master.withColumn(\"zips\",explode(df_store_grp_master.zip)) \\\r\n",
					"                                     .withColumnRenamed(\"grp_id\",\"grp_id_zip\").select(\"grp_id_zip\",\"zips\")\r\n",
					"\r\n",
					"df_stor_grp_stor_num = df_store_grp_master.withColumn(\"loc_nums\",explode(df_store_grp_master.store_numbers)) \\\r\n",
					"                                          .withColumnRenamed(\"grp_id\",\"grp_id_stor_num\").select(\"grp_id_stor_num\",\"loc_nums\")\r\n",
					"\r\n",
					"df_stor_grp_pr_zone_id = df_store_grp_master.withColumn(\"price_zones\",explode(df_store_grp_master.price_zone_ids)) \\\r\n",
					"                                            .withColumnRenamed(\"grp_id\",\"grp_id_pr_zone\").select(\"grp_id_pr_zone\",\"price_zones\")\r\n",
					"\r\n",
					"df_svc_loc_stor_grp=df_svc_locs_selected.join(df_stor_grp_ecom_stor_id,df_svc_locs_selected.ecomm_store_id==df_stor_grp_ecom_stor_id.ecom_storeIds,\"left\") \\\r\n",
					"                                                  .join(df_stor_grp_zip,df_svc_locs_selected.zip==df_stor_grp_zip.zips,\"left\") \\\r\n",
					"                                                  .join(df_stor_grp_stor_num,df_svc_locs_selected.location_number==df_stor_grp_stor_num.loc_nums,\"left\") \\\r\n",
					"                                                  .join(df_stor_grp_pr_zone_id,df_svc_locs_selected.price_zone==df_stor_grp_pr_zone_id.price_zones,\"left\") \\\r\n",
					"                                                  .drop(\"ecom_storeIds\",\"zips\",\"loc_nums\",\"price_zones\")\r\n",
					"\r\n",
					"\r\n",
					"df_grouped_stor_grp=df_svc_loc_stor_grp.groupBy(\"ecomm_store_id\",\"zip\",\"location_number\",\"price_zone\").agg(\r\n",
					"                                        F.collect_list (\"grp_id_ecom\").alias(\"grp_id_ecom_lst\"),\r\n",
					"                                        F.collect_list (\"grp_id_zip\").alias(\"grp_id_zip_lst\"),\r\n",
					"                                        F.collect_list (\"grp_id_stor_num\").alias(\"grp_id_stor_num_lst\"),\r\n",
					"                                        F.collect_list (\"grp_id_pr_zone\").alias(\"grp_id_pr_zone_lst\")\r\n",
					"                                    )\r\n",
					"df_enriched_stor_grp=df_grouped_stor_grp.withColumn(\"stor_grps\",F.concat(\"grp_id_ecom_lst\",\"grp_id_zip_lst\",\"grp_id_stor_num_lst\",\"grp_id_pr_zone_lst\")) \\\r\n",
					"                     .select(\"ecomm_store_id\",\"zip\",\"location_number\",\"price_zone\",F.array_distinct(\"stor_grps\").alias(\"store_groups\"))"
				],
				"execution_count": 400
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**JOINING MINIMUM ORDER FOR CHECKOUT, LEGACY FEE AMOUNTS & FEES WITH SERVICE LOCATION**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"tdf_service_locations=df_service_locs.join(df_minorder, \\\r\n",
					"                                            ((df_service_locs.ecomm_store_id==df_minorder.ecom_stor_id) & \\\r\n",
					"                                            (df_service_locs.user_type==df_minorder.user_type_cd)&\r\n",
					"                                            (df_service_locs.id==df_minorder.stor_zip_id)),\"left\") \\\r\n",
					"                                        .join(df_enriched_stor_grp, on=[\"ecomm_store_id\",\"zip\",\"location_number\",\"price_zone\"], how=\"left\") \\\r\n",
					"                                        .select(df_service_locs[\"id\"], \\\r\n",
					"                                                df_service_locs[\"location_number\"], \\\r\n",
					"                                                df_service_locs[\"physical_grocery_store\"], \\\r\n",
					"                                                df_service_locs[\"ecomm_store_id\"], \\\r\n",
					"                                                df_service_locs[\"opco\"], \\\r\n",
					"                                                df_service_locs[\"name\"], \\\r\n",
					"                                                df_service_locs[\"address\"], \\\r\n",
					"                                                df_service_locs[\"address2\"], \\\r\n",
					"                                                df_service_locs[\"city\"], \\\r\n",
					"                                                df_service_locs[\"state\"], \\\r\n",
					"                                                df_service_locs[\"pickup_point_type\"], \\\r\n",
					"                                                df_service_locs[\"zip\"], \\\r\n",
					"                                                df_service_locs[\"map_url\"], \\\r\n",
					"                                                df_service_locs[\"location\"], \\\r\n",
					"                                                df_service_locs[\"phone_number\"], \\\r\n",
					"                                                df_service_locs[\"active\"], \\\r\n",
					"                                                df_service_locs[\"web_active\"], \\\r\n",
					"                                                df_service_locs[\"instructions\"], \\\r\n",
					"                                                df_service_locs[\"user_type\"], \\\r\n",
					"                                                df_service_locs[\"delivery_area_id\"], \\\r\n",
					"                                                df_service_locs[\"time_diff_qy\"], \\\r\n",
					"                                                df_service_locs[\"price_zone\"], \\\r\n",
					"                                                df_service_locs[\"subscription_price_zone\"], \\\r\n",
					"                                                df_service_locs[\"service_type\"], \\\r\n",
					"                                                df_service_locs[\"store_status_code\"], \\\r\n",
					"                                                df_service_locs[\"tax_grp_cd\"], \\\r\n",
					"                                                df_service_locs[\"pickup_location_id\"], \\\r\n",
					"                                                df_service_locs[\"checked_pickup_location_id\"], \\\r\n",
					"                                                df_service_locs[\"store_staging_only\"], \\\r\n",
					"                                                df_service_locs[\"pup_staging_only\"], \\\r\n",
					"                                                df_service_locs[\"pickup_sibling\"], \\\r\n",
					"                                                df_service_locs[\"store_id\"], \\\r\n",
					"                                                df_enriched_stor_grp[\"store_groups\"], \\\r\n",
					"                                                df_LegFee[\"legacy_fee_amounts\"], \\\r\n",
					"                                                df_service_locs[\"fees\"], \\\r\n",
					"                                                df_minorder[\"minimum_order_for_checkout\"], \\\r\n",
					"                                                df_service_locs[\"site\"], \\\r\n",
					"                                                df_service_locs[\"pickup_sibling_enabled\"], \\\r\n",
					"                                                df_service_locs[\"pickup_sibling_site\"], \\\r\n",
					"                                                df_service_locs[\"ortec_enabled\"], \\\r\n",
					"                                                df_service_locs[\"location_centroid\"], \\\r\n",
					"                                                df_service_locs[\"pup_id\"]\r\n",
					"                                                     )\r\n",
					"logger.info(\"\\t SERVICE LOCATION: Service locations target df processed. \\n OPCO = {0},\\n Count={1}\".format(OPCO,tdf_service_locations.count()))"
				],
				"execution_count": 401
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**VALIDATING DATA & PERSISTING INTEGRATED SERVICE LOCATIONS**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def check_if_master_file_exists():    \r\n",
					"    return DeltaTable.isDeltaTable(spark, BASE_ADLS_CONN_STR + TARGET_SERVICE_LOCATION.format(opco = OPCO))\r\n",
					"\r\n",
					"def load_service_locations(df_load,path,opco):\r\n",
					"    df_load\\\r\n",
					"            .write \\\r\n",
					"            .option(\"mergeSchema\", \"true\") \\\r\n",
					"            .mode(\"overwrite\") \\\r\n",
					"            .format(\"delta\") \\\r\n",
					"            .save(path)\r\n",
					"    logger.info(\"\\t SERVICE LOCATION: Service locations master data is written.\\n OPCO = {0},\\n Path={1},\\n Count={2}\".format(OPCO,TARGET_SERVICE_LOCATION.format(opco = OPCO),df_load.count()))\r\n",
					"\r\n",
					"# main starts here\r\n",
					"is_master_fl_exist = check_if_master_file_exists()\r\n",
					"if is_master_fl_exist: \r\n",
					"    tdf_svc_loc_master= spark \\\r\n",
					"                                .read \\\r\n",
					"                                .format(\"delta\") \\\r\n",
					"                                .load(BASE_ADLS_CONN_STR + TARGET_SERVICE_LOCATION.format(opco = OPCO))\r\n",
					"    logger.info(\"\\t SERVICE LOCATION: Service locations loaded from master. OPCO = {0}, Count={1}\".format(OPCO, tdf_svc_loc_master.count()))\r\n",
					"    is_val_success= validate_count(tdf_svc_loc_master,tdf_service_locations,VAL_CNT_THRESHOLD)        \r\n",
					"    if is_val_success :\r\n",
					"        load_service_locations(tdf_service_locations,BASE_ADLS_CONN_STR + TARGET_SERVICE_LOCATION.format(opco = OPCO), OPCO)\r\n",
					"    else:\r\n",
					"        logger.error(\"\\t Failed to override master since threshold is exceding \")\r\n",
					"        raise Exception(\"EXCEEDING_THRESHOLD\")                             \r\n",
					"else:\r\n",
					"        logger.info(\"\\t First Time Master Load\")\r\n",
					"        load_service_locations(tdf_service_locations,BASE_ADLS_CONN_STR + TARGET_SERVICE_LOCATION.format(opco = OPCO), OPCO)\r\n",
					""
				],
				"execution_count": 402
			}
		]
	}
}